{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f263d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54fdf9f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Draw the face detection annotations on the image.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n\u001b[0;32m     28\u001b[0m mp_drawing\u001b[38;5;241m.\u001b[39mdraw_landmarks(\n\u001b[0;32m     29\u001b[0m     image,\n\u001b[0;32m     30\u001b[0m     result2\u001b[38;5;241m.\u001b[39mpose_landmarks,\n\u001b[0;32m     31\u001b[0m     mp_pose\u001b[38;5;241m.\u001b[39mPOSE_CONNECTIONS,\n\u001b[0;32m     32\u001b[0m     landmark_drawing_spec\u001b[38;5;241m=\u001b[39mmp_drawing_styles\u001b[38;5;241m.\u001b[39mget_default_pose_landmarks_style())\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# detection 내부에 bbox 좌표와 point 들의 좌표값이 x,y, score로 설정되어 있음\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MediaPipe의 얼굴 감지, 그리기 유틸리티, 포즈 감지 모듈을 불러옵니다.\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\"\"\"\n",
    "mp.solutions.drawing_utils:\n",
    "이 모듈은 랜드마크(landmarks)를 이미지 위에 그리는 데 사용되는 유틸리티 함수들을 제공합니다.\n",
    "예를 들어, 감지된 얼굴이나 포즈의 랜드마크를 이미지 위에 시각적으로 표시하고 싶을 때 draw_landmarks 함수를 사용할 수 있습니다.\n",
    "\n",
    "mp.solutions.drawing_styles:\n",
    "이 모듈은 drawing_utils에서 랜드마크를 그릴 때 사용할 수 있는 스타일과 색상 설정을 정의합니다.\n",
    "예를 들어, 랜드마크나 연결선의 색상, 두께 등을 지정할 때 사용할 수 있는 스타일 객체를 제공합니다.\n",
    "\n",
    "간단히 말하자면, drawing_utils는 그리기 기능 자체를 담당하며, drawing_styles는 그리는 방식을 꾸며주는 스타일을 정의하는 데 사용됩니다.\n",
    "이를 통해 개발자는 랜드마크를 그릴 때 일관되고 커스텀 가능한 스타일을 적용할 수 있습니다.\"\"\"\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# 웹캠을 사용하기 위해 VideoCapture 객체를 초기화합니다.\n",
    "cap = cv2.VideoCapture(0)\n",
    "# 얼굴 감지 및 포즈 객체를 초기화합니다.\n",
    "\"\"\"백슬래시(\\)는 파이썬에서 라인을 연속으로 이어주는 문자\"\"\"\n",
    "with mp_face_detection.FaceDetection(\n",
    "    model_selection=0, min_detection_confidence=0.5) as face_detection,\\\n",
    "    mp_pose.Pose(\n",
    "      min_detection_confidence = 0.5,\n",
    "      min_tracking_confidence = 0.5) as pose:\n",
    "  # 웹캠이 열려있는 동안 반복합니다.\n",
    "  while cap.isOpened():\n",
    "    # 웹캠으로부터 프레임을 읽어옵니다.\n",
    "    success, image = cap.read()\n",
    "    # 프레임을 읽지 못했으면 경고를 출력하고 다음 프레임으로 넘어갑니다.\n",
    "    if not success:\n",
    "      print(\"빈 카메라 프레임을 무시합니다.\")\n",
    "      continue\n",
    "\n",
    "    # 성능 향상을 위해 이미지를 수정 불가로 설정합니다.\n",
    "    image.flags.writeable = False\n",
    "    # 이미지를 BGR에서 RGB로 변환합니다.\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # 얼굴 감지를 수행합니다.\n",
    "    result1 = face_detection.process(image)\n",
    "    # 포즈 감지를 수행합니다.\n",
    "    result2 = pose.process(image)\n",
    "\n",
    "    # 이미지를 다시 쓰기 가능하게 하고 BGR로 다시 변환합니다.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # 포즈 랜드마크를 그립니다.\n",
    "    if result2.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            result2.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "    \n",
    "    # 감지된 얼굴에 대한 주석을 그립니다.\n",
    "    if result1.detections:\n",
    "      for detection in result1.detections:\n",
    "        mp_drawing.draw_detection(image, detection)\n",
    "    \n",
    "    # 이미지를 수평으로 뒤집어서 자기 자신을 보는 것처럼 표시합니다.\n",
    "    cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))\n",
    "    # ESC 키를 누르면 반복을 종료합니다.\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "\n",
    "# VideoCapture 객체를 해제합니다.\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5435b16f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
