{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d2750b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac6857ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "# 비디오 파일 목록과 태그를 포함하는 리스트를 만드는 함수\n",
    "def create_data_list(data_dir):\n",
    "    data_list = []\n",
    "    # data_dir 안의 각 디렉토리에 대해 반복\n",
    "    for item in os.listdir(data_dir):\n",
    "        item_path = os.path.join(data_dir, item)  # 아이템의 전체 경로\n",
    "        # 해당 경로가 디렉토리인지 확인\n",
    "        if os.path.isdir(item_path):\n",
    "            # 디렉토리 내의 모든 파일을 나열\n",
    "            for file_name in os.listdir(item_path):\n",
    "                # 파일이 .mp4 파일인지 확인\n",
    "                if file_name.endswith('.mp4'):\n",
    "                    # 리스트에 태그와 파일 경로를 추가\n",
    "                    data_list.append((item, str('dataset/test'+'/'+item)+'/'+file_name))\n",
    "    return data_list\n",
    "\n",
    "# 함수를 사용해서 리스트를 생성\n",
    "train_list = create_data_list(train_dir)\n",
    "test_list = create_data_list(test_dir)\n",
    "# 리스트에서 데이터프레임을 생성\n",
    "train_df = pd.DataFrame(data=train_list, columns=['tag', 'video_name'])\n",
    "test_df = pd.DataFrame(data=test_list, columns=['tag', 'video_name'])\n",
    "# 필요한 경우 열 순서를 수정\n",
    "train_df = train_df.loc[:, ['tag', 'video_name']]\n",
    "test_df = test_df.loc[:, ['tag', 'video_name']]\n",
    "# 데이터프레임을 CSV 파일로 저장\n",
    "train_file_path = 'train.csv'\n",
    "test_file_path = 'test.csv'\n",
    "train_df.to_csv(train_file_path, encoding='utf-8-sig', index=False)\n",
    "test_df.to_csv(test_file_path, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1756281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total video for training: 10\n",
      "Total video for testing: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>video_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>보내다</td>\n",
       "      <td>dataset/test/보내다/1.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>알다</td>\n",
       "      <td>dataset/test/알다/1.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>월요일</td>\n",
       "      <td>dataset/test/월요일/1.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>가치</td>\n",
       "      <td>dataset/test/가치/1.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>보관</td>\n",
       "      <td>dataset/test/보관/1.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tag              video_name\n",
       "5  보내다  dataset/test/보내다/1.mp4\n",
       "8   알다   dataset/test/알다/1.mp4\n",
       "9  월요일  dataset/test/월요일/1.mp4\n",
       "3   가치   dataset/test/가치/1.mp4\n",
       "4   보관   dataset/test/보관/1.mp4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "print(f\"Total video for training: {len(train_df)}\")\n",
    "print(f\"Total video for testing: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85a9b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, smooth_landmarks=True)\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b79c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 이미지에서 중앙에 맞춰 정사각형으로 잘나내는 함수\n",
    "def crop_center_square(frame):\n",
    "    # 이미지의 높이(y)와 너비(x)를 가져옴\n",
    "    y, x = frame.shape[0:2]\n",
    "    # 이미지의 높이와 너비 중 더 작은 값을 선택하여 정사각형의 크기를 결정\n",
    "    min_dim = min(y, x)\n",
    "    # 정사각형을 이미지 중앙에 위치시키기 위해 시작점의 x좌표와 y좌표를 계산\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    # 계산된 시작점과 정사각형의 크기를 이용하여 이미지의 중앙 부분을 잘라냅니다.\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "# 비디오 파일을 로드하고, 각 프레임을 처리하여 배열로 반환하는 함수\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    # OpenCV를 사용하여 비디오 파일 열기\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    skeletons = []  # 스켈레톤 데이터\n",
    "    hand_landmarks = []  # 손 데이터\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # 비디오에서 프레임을 하나씩 읽기\n",
    "            ret, frame = cap.read()\n",
    "            # 읽을 프레임이 없으면 반복문을 종료\n",
    "            if not ret:\n",
    "                break\n",
    "            # 읽은 프레임에서 중앙의 정사각형 부분을 잘라냄\n",
    "            frame = crop_center_square(frame)\n",
    "            # 프레임의 크기를 지정된 크기로 조절\n",
    "            frame = cv2.resize(frame, resize)            \n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Mediapipe를 사용하여 스켈레톤 추출\n",
    "            hands_results = hands.process(frame_rgb)\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "           \n",
    "            if pose_results.pose_landmarks:\n",
    "                skeletons.append(pose_results.pose_landmarks.landmark)\n",
    "            if hands_results.multi_hand_landmarks:\n",
    "                hand_landmarks.append(hands_results.multi_hand_landmarks)\n",
    "            \n",
    "            # OpenCV는 BGR 색상 순서를 사용하므로, 이를 RGB 순서로 변경\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            # 처리된 프레임을 프레임 리스트에 추가\n",
    "            frames.append(frame)\n",
    "            # max_frames가 지정된 경우, 지정된 수의 프레임만큼만 처리\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        # 비디오 파일을 닫기\n",
    "        cap.release()\n",
    "        pose.close\n",
    "        hands.close\n",
    "    # 처리된 모든 프레임을 numpy 배열로 변환하여 반환\n",
    "    return np.array(frames), skeletons, hand_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bfeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징추출\n",
    "def build_feature_extractor():\n",
    "    # 이미지 특징 추출을 위한 InceptionV3 모델\n",
    "    base_model = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "    image_input = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed_image = preprocess_input(image_input)\n",
    "    image_features = base_model(preprocessed_image)\n",
    "\n",
    "    # Mediapipe 데이터를 위한 입력 레이어 및 처리 레이어\n",
    "    # 예시로, Mediapipe 데이터의 차원을 상정하여 입력 레이어를 정의\n",
    "    mediapipe_input = keras.Input((1599+63,))\n",
    "    mediapipe_features = keras.layers.Dense(128, activation=\"relu\")(mediapipe_input)\n",
    "\n",
    "    # 이미지 특징과 Mediapipe 데이터의 결합\n",
    "    combined_features = keras.layers.concatenate([image_features, mediapipe_features])\n",
    "\n",
    "    # 최종 모델\n",
    "    outputs = keras.layers.Dense(10, activation=\"softmax\")(combined_features)\n",
    "    return keras.Model(inputs=[image_input, mediapipe_input], outputs=outputs, name=\"feature_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5cf12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5f2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e5d1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae3a9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617610e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2e8e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01dde2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f10b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea048062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29eaa11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69418a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
