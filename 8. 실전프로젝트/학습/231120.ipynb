{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e179d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_docs.vis import embed  # TensorFlow 문서의 시각화를 위한 도구\n",
    "from tensorflow import keras  # TensorFlow의 고수준 신경망 API\n",
    "from imutils import paths  # 이미지 처리를 위한 유틸리티 함수들을 제공\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt  # 그래프와 이미지를 시각화하기 위한 라이브러리\n",
    "import tensorflow as tf  # TensorFlow 라이브러리, 딥러닝 모델을 구성하고 훈련하기 위해 사용\n",
    "import pandas as pd  # 데이터 분석 및 조작을 위한 라이브러리\n",
    "import numpy as np  # 수치 계산을 위한 라이브러리\n",
    "import imageio  # 이미지 읽기/쓰기를 위한 라이브러리\n",
    "import cv2  # OpenCV 라이브러리, 이미지 및 비디오 처리를 위해 사용\n",
    "import os  # 운영체제와 상호작용을 위한 라이브러리\n",
    "import math\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b57e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video/dataset/train/가볍다/1.mp4</td>\n",
       "      <td>가볍다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video/dataset/train/가져오다/2.mp4</td>\n",
       "      <td>가져오다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video/dataset/train/가짜/3.mp4</td>\n",
       "      <td>가짜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video/dataset/train/가치/4.mp4</td>\n",
       "      <td>가치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video/dataset/train/보관/5.mp4</td>\n",
       "      <td>보관</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>video/dataset/train/보내다/6.mp4</td>\n",
       "      <td>보내다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>video/dataset/train/보다/7.mp4</td>\n",
       "      <td>보다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>video/dataset/train/안경/8.mp4</td>\n",
       "      <td>안경</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>video/dataset/train/알다/9.mp4</td>\n",
       "      <td>알다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>video/dataset/train/월요일/10.mp4</td>\n",
       "      <td>월요일</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       video_name   tag\n",
       "0   video/dataset/train/가볍다/1.mp4   가볍다\n",
       "1  video/dataset/train/가져오다/2.mp4  가져오다\n",
       "2    video/dataset/train/가짜/3.mp4    가짜\n",
       "3    video/dataset/train/가치/4.mp4    가치\n",
       "4    video/dataset/train/보관/5.mp4    보관\n",
       "5   video/dataset/train/보내다/6.mp4   보내다\n",
       "6    video/dataset/train/보다/7.mp4    보다\n",
       "7    video/dataset/train/안경/8.mp4    안경\n",
       "8    video/dataset/train/알다/9.mp4    알다\n",
       "9  video/dataset/train/월요일/10.mp4   월요일"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = os.listdir('video/dataset/train')\n",
    "label_types = os.listdir('video/dataset/train')\n",
    "# 훈련 데이터셋을 위한 비어있는 리스트 초기화\n",
    "rooms = []\n",
    "# dataset_path에 저장된 각 항목(방 유형)에 대해 반복\n",
    "for item in dataset_path:\n",
    "    # 'dataset/train' 폴더 내 각 방 유형별로 모든 파일 이름을 가져옴\n",
    "    all_rooms = os.listdir('video/dataset/train'+'/'+item)    \n",
    "    # 가져온 파일 이름을 rooms 리스트에 추가\n",
    "    for room in all_rooms:\n",
    "        rooms.append((item, str('video/dataset/train'+'/'+item)+'/'+room))\n",
    "# rooms 리스트를 사용하여 데이터프레임 생성\n",
    "train_df = pd.DataFrame(data=rooms, columns=['tag','video_name']).loc[:,['video_name','tag']]\n",
    "df = train_df.loc[:,['video_name','tag']]\n",
    "# 생성된 데이터프레임을 CSV 파일로 저장\n",
    "df.to_csv('train.csv', encoding='utf-8-sig')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f16b7170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video/dataset/test/가볍다/1.mp4</td>\n",
       "      <td>가볍다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video/dataset/test/가져오다/2.mp4</td>\n",
       "      <td>가져오다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video/dataset/test/가짜/3.mp4</td>\n",
       "      <td>가짜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video/dataset/test/가치/4.mp4</td>\n",
       "      <td>가치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video/dataset/test/보관/5.mp4</td>\n",
       "      <td>보관</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>video/dataset/test/보내다/6.mp4</td>\n",
       "      <td>보내다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>video/dataset/test/보다/7.mp4</td>\n",
       "      <td>보다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>video/dataset/test/안경/8.mp4</td>\n",
       "      <td>안경</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>video/dataset/test/알다/9.mp4</td>\n",
       "      <td>알다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>video/dataset/test/월요일/10.mp4</td>\n",
       "      <td>월요일</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      video_name   tag\n",
       "0   video/dataset/test/가볍다/1.mp4   가볍다\n",
       "1  video/dataset/test/가져오다/2.mp4  가져오다\n",
       "2    video/dataset/test/가짜/3.mp4    가짜\n",
       "3    video/dataset/test/가치/4.mp4    가치\n",
       "4    video/dataset/test/보관/5.mp4    보관\n",
       "5   video/dataset/test/보내다/6.mp4   보내다\n",
       "6    video/dataset/test/보다/7.mp4    보다\n",
       "7    video/dataset/test/안경/8.mp4    안경\n",
       "8    video/dataset/test/알다/9.mp4    알다\n",
       "9  video/dataset/test/월요일/10.mp4   월요일"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = os.listdir('video/dataset/test')\n",
    "room_types = os.listdir('video/dataset/test')\n",
    "\n",
    "rooms = []\n",
    "# dataset_path에 저장된 각 항목(방 유형)에 대해 반복\n",
    "for item in dataset_path:\n",
    "    # 'dataset/test' 폴더 내 각 방 유형별로 모든 파일 이름을 가져옴\n",
    "    all_rooms = os.listdir('video/dataset/test'+'/'+item)\n",
    "    # 가져온 파일 이름을 rooms 리스트에 추가\n",
    "    for room in all_rooms:\n",
    "        rooms.append((item, str('video/dataset/test'+'/'+item)+'/'+room))\n",
    "\n",
    "# rooms 리스트를 사용하여 데이터프레임 생성\n",
    "train_df = pd.DataFrame(data=rooms, columns=['tag','video_name'])\n",
    "df = train_df.loc[:,['video_name','tag']]\n",
    "# 생성된 데이터프레임을 CSV 파일로 저장\n",
    "df.to_csv('test.csv', encoding='utf-8-sig')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b1470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 설정\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# GPU가 사용 가능한 경우\n",
    "if gpus:\n",
    "    try:\n",
    "        # 첫 번째 GPU에 대해 메모리 제한 설정\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0], \n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)]\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4eed616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total video for training: 10\n",
      "Total video for testing: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>video/dataset/train/보다/7.mp4</td>\n",
       "      <td>보다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>video/dataset/train/월요일/10.mp4</td>\n",
       "      <td>월요일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>video/dataset/train/보관/5.mp4</td>\n",
       "      <td>보관</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>video/dataset/train/가볍다/1.mp4</td>\n",
       "      <td>가볍다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>video/dataset/train/가져오다/2.mp4</td>\n",
       "      <td>가져오다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      video_name   tag\n",
       "6           6    video/dataset/train/보다/7.mp4    보다\n",
       "9           9  video/dataset/train/월요일/10.mp4   월요일\n",
       "4           4    video/dataset/train/보관/5.mp4    보관\n",
       "0           0   video/dataset/train/가볍다/1.mp4   가볍다\n",
       "1           1  video/dataset/train/가져오다/2.mp4  가져오다"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 데이터셋과 테스트 데이터셋을 각각 CSV 파일에서 로드\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# 훈련 및 테스트 데이터셋 크기 출력\n",
    "print(f\"Total video for training: {len(train_df)}\")\n",
    "print(f\"Total video for testing: {len(test_df)}\")\n",
    "\n",
    "# 훈련 데이터셋의 샘플 5개 출력\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51d4abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, smooth_landmarks=True)\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e86db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지의 크기, 배치 크기, 에포크 수를 정의하는 하이퍼파라미터입니다.\n",
    "IMG_SIZE = 224  # 입력 이미지의 크기를 정의합니다.\n",
    "BATCH_SIZE = 64  # 한 번에 처리할 이미지의 수를 정의합니다.\n",
    "EPOCHS = 10  # 모델을 훈련할 때 전체 데이터셋을 반복할 횟수를 정의합니다.\n",
    "\n",
    "# 비디오 처리에 사용할 최대 시퀀스 길이와 특징 벡터의 크기를 정의합니다.\n",
    "MAX_SEQ_LENGTH = 20  # 처리할 비디오의 최대 프레임 수를 정의합니다.\n",
    "NUM_FEATURES = 2048  # 비디오 프레임에서 추출할 특징의 차원 수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99a0f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 이미지에서 중앙에 맞춰 정사각형으로 잘나내는 함수\n",
    "def crop_center_square(frame):\n",
    "    # 이미지의 높이(y)와 너비(x)를 가져옴\n",
    "    y, x = frame.shape[0:2]\n",
    "    # 이미지의 높이와 너비 중 더 작은 값을 선택하여 정사각형의 크기를 결정\n",
    "    min_dim = min(y, x)\n",
    "    # 정사각형을 이미지 중앙에 위치시키기 위해 시작점의 x좌표와 y좌표를 계산\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    # 계산된 시작점과 정사각형의 크기를 이용하여 이미지의 중앙 부분을 잘라냅니다.\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abc2486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 파일을 로드하고, 각 프레임을 처리하여 배열로 반환하는 함수\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    # OpenCV를 사용하여 비디오 파일 열기\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    skeletons = []  # 스켈레톤 데이터\n",
    "    hand_landmarks = []  # 손 데이터\n",
    "    face_landmarks = []  # 얼굴 데이터\n",
    "    try:\n",
    "        while True:            \n",
    "            ret, frame = cap.read() # 비디오에서 프레임을 하나씩 읽기            \n",
    "            if not ret:\n",
    "                break # 읽을 프레임이 없으면 반복문을 종료\n",
    "            frame = crop_center_square(frame)             # 읽은 프레임에서 중앙의 정사각형 부분을 잘라냄            \n",
    "            frame = cv2.resize(frame, resize)            # 프레임의 크기를 지정된 크기로 조절\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)            \n",
    "            # Mediapipe를 사용하여 스켈레톤 추출\n",
    "            hands_results = hands.process(frame_rgb)\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "            face_results = face_detection.process(frame_rgb)\n",
    "           \n",
    "            if pose_results.pose_landmarks:\n",
    "                skeletons.append(pose_results.pose_landmarks.landmark)\n",
    "            if hands_results.multi_hand_landmarks:\n",
    "                hand_landmarks.append(hands_results.multi_hand_landmarks)\n",
    "            if face_results.detections:\n",
    "                face_landmarks.append(face_results.detections)\n",
    "            \n",
    "            # OpenCV는 BGR 색상 순서를 사용하므로, 이를 RGB 순서로 변경\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            # 처리된 프레임을 프레임 리스트에 추가\n",
    "            frames.append(frame)\n",
    "            # max_frames가 지정된 경우, 지정된 수의 프레임만큼만 처리\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        # 비디오 파일을 닫기\n",
    "        cap.release()\n",
    "        pose.close\n",
    "        hands.close\n",
    "        face_detection.close\n",
    "    # 처리된 모든 프레임을 numpy 배열로 변환하여 반환\n",
    "    return np.array(frames), skeletons, hand_landmarks, face_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "315239fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징추출 함수\n",
    "def build_feature_extractor():\n",
    "    # 이미지 특징 추출을 위한 InceptionV3 모델\n",
    "    # InceptionV3 모델을 특징 추출기로 사용.\n",
    "    # ImageNet 데이터로 사전 훈련된 가중치를 사용하고, 최상위 층은 포함하지 않으며, 평균 풀링을 사용\n",
    "    base_model = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    # InceptionV3에 맞게 입력 데이터를 전처리하는 함수\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "    # 모델의 입력을 정의\n",
    "    image_input = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    # 입력 데이터를 전처리\n",
    "    preprocessed_image = preprocess_input(image_input)\n",
    "    image_features = base_model(preprocessed_image)\n",
    "\n",
    "    # Mediapipe 데이터를 위한 입력 레이어 및 처리 레이어\n",
    "    # 예시로, Mediapipe 데이터의 차원을 상정하여 입력 레이어를 정의\n",
    "    mediapipe_input = keras.Input((1599+63,))\n",
    "    mediapipe_features = keras.layers.Dense(128, activation=\"relu\")(mediapipe_input)\n",
    "\n",
    "    # 이미지 특징과 Mediapipe 데이터의 결합\n",
    "    combined_features = keras.layers.concatenate([image_features, mediapipe_features])\n",
    "\n",
    "    # 최종 모델\n",
    "    outputs = keras.layers.Dense(10, activation=\"softmax\")(combined_features)\n",
    "    return keras.Model(inputs=[image_input, mediapipe_input], outputs=outputs, name=\"feature_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98f5032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징 추출기 모델을 생성\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23577e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가볍다', '가져오다', '가짜', '가치', '보관', '보내다', '보다', '안경', '알다', '월요일']\n"
     ]
    }
   ],
   "source": [
    "# 클래스 라벨을 정수로 변환하는 레이어를 생성\n",
    "label_processor = keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"])\n",
    ")\n",
    "# 라벨 프로세서가 이해하는 어휘목록을 출력\n",
    "print(label_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ee889b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (frame_features, frame_masks), labels\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# 훈련 데이터와 라벨을 준비합니다.\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m train_data, train_labels \u001b[38;5;241m=\u001b[39m prepare_all_videos(train_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# 테스트 데이터와 라벨을 준비합니다.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m test_data, test_labels \u001b[38;5;241m=\u001b[39m prepare_all_videos(test_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[28], line 19\u001b[0m, in \u001b[0;36mprepare_all_videos\u001b[1;34m(df, root_dir)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(video_paths):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# 모든 프레임을 수집하고 배치 차원을 추가합니다.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     frames \u001b[38;5;241m=\u001b[39m load_video(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_dir, path))\n\u001b[1;32m---> 19\u001b[0m     frames \u001b[38;5;241m=\u001b[39m frames[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# 현재 비디오의 마스크와 특징을 저장하기 위한 임시 공간을 초기화합니다.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     temp_frame_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m     23\u001b[0m         shape\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m     24\u001b[0m             \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "# 주어진 데이터프레임(df)과 루트 디렉터리(root_dir)를 사용하여 모든 비디오를 준비하는 함수입니다.\n",
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)  # 샘플의 수를 결정합니다.\n",
    "    video_paths = df[\"video_name\"].values.tolist()  # 비디오 경로를 리스트로 변환합니다.\n",
    "    labels = df[\"tag\"].values  # 라벨 값을 가져옵니다.\n",
    "    labels = label_processor(labels[..., None]).numpy()  # 라벨을 처리하여 넘파이 배열로 변환합니다.\n",
    "\n",
    "    # `frame_masks`와 `frame_features`는 우리의 순차 모델에 제공될 데이터입니다.\n",
    "    # `frame_masks`는 시간 단계가 패딩으로 마스킹되었는지 여부를 나타내는 부울 값들을 포함합니다.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # 각 비디오에 대해서.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # 모든 프레임을 수집하고 배치 차원을 추가합니다.\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # 현재 비디오의 마스크와 특징을 저장하기 위한 임시 공간을 초기화합니다.\n",
    "        temp_frame_mask = np.zeros(\n",
    "            shape=(\n",
    "                1,\n",
    "                MAX_SEQ_LENGTH,\n",
    "            ),\n",
    "            dtype=\"bool\",\n",
    "        )\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # 현재 비디오의 프레임에서 특징을 추출합니다.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                # 특징 추출기를 사용하여 각 프레임의 특징을 예측합니다.\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                )\n",
    "            # 마스크를 설정합니다. 1 = 마스킹되지 않음, 0 = 마스킹됨\n",
    "            temp_frame_mask[i, :length] = 1  \n",
    "\n",
    "        # 임시 특징과 마스크를 각각의 특징 및 마스크 배열에 할당합니다.\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    # 특징과 마스크 배열, 라벨을 반환합니다.\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "# 훈련 데이터와 라벨을 준비합니다.\n",
    "train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
    "# 테스트 데이터와 라벨을 준비합니다.\n",
    "test_data, test_labels = prepare_all_videos(test_df, \"test\")\n",
    "\n",
    "# 훈련 데이터 세트의 프레임 특징과 마스크의 차원을 출력합니다.\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ec7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
