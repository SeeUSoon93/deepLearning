{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1zMpeIDQcgv2aeRxIr9pUmpzEo7NW2rSF",
      "authorship_tag": "ABX9TyNK7ho4ghDw6CsvJN5Lw2Oy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeeUSoon93/MachineLerning/blob/main/ex03_%EB%8B%AE%EC%9D%80_%EA%BC%B4_%EC%95%B1_%EB%A7%8C%EB%93%A4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZg_tQNT_q_p",
        "outputId": "cc502ec1-452e-4c76-fb1b-0c6db0571842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "# 현재 작업 디렉토리 확인\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 작업 디렉토리 변경\n",
        "%cd \"drive/MyDrive/Colab Notebooks/DeepLearning\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fGRwKhuMf0o",
        "outputId": "b44e49ff-4e1f-4936-d6ec-e7f44444916b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/DeepLearning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리, 모듈 로딩\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm # 반복문의 진행률을 보여주는 도구\n",
        "from tensorflow.keras.utils import image_dataset_from_directory # 폴더에서 이미지를 로딩해주는 모듈(함수)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import InceptionV3 # 이미지 특징 추출 도구\n",
        "from tensorflow.keras.models import Sequential # 모델의 뼈대를 만드는 도구\n",
        "from tensorflow.keras.layers import Dense # 퍼셉트론(뉴런)의 묶음을 표현하는 클래스\n",
        "from tensorflow.keras.callbacks import EarlyStopping # 조기학습중단\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint # 모델자동저장\n",
        "from tensorflow.keras.models import load_model # hdf5 포멧의 모델파일을 로딩하는 함수\n",
        "from sklearn.metrics import classification_report # 분류평가지표 확인 함수"
      ],
      "metadata": {
        "id": "AgOyiF5dMkHu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 압축풀기\n",
        "!unzip ./data/face.zip -d ./data/face/"
      ],
      "metadata": {
        "id": "2ygvrnVAMtsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data = image_dataset_from_directory(\n",
        "    directory=\"./data/face/face\",    # 읽을 폴더의 경로 설정\n",
        "    labels = \"inferred\",    # 폴더명을 인식해서 정답으로 붙여준다.\n",
        "    label_mode = \"categorical\",    # 다중분류 형태로 정답 생성\n",
        "    color_mode = \"rgb\",    # 컬러사진 설정\n",
        "    image_size = (224,224),    # 이미지 크기 리사이징\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqEaUS-jMxx4",
        "outputId": "dd09bca0-ea33-4136-a39a-3e52a39f689c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3987 files belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = []\n",
        "y_data = []"
      ],
      "metadata": {
        "id": "k30b9yaqM9xQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in tqdm(total_data.as_numpy_iterator()) :\n",
        "  X_data.append(img)\n",
        "  y_data.append(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MxY85SBM-SW",
        "outputId": "c6426658-8f23-4175-c0fc-d21edec398ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "63it [01:42,  4.52s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 리스트에 32장씩 담겨있는 사진데이터 및 정답데이터를 하나의 넘파이로 통합\n",
        "\n",
        "X_numpy = np.concatenate(X_data)\n",
        "y_numpy = np.concatenate(y_data)"
      ],
      "metadata": {
        "id": "62R_RnkyNANO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_numpy.shape, y_numpy.shape"
      ],
      "metadata": {
        "id": "xdC6zvd7NBzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy 데이터 저장\n",
        "# 매번 이미지를 읽어들이면 시간이 오래걸리기 때문에\n",
        "# 읽어들인 numpy를 파일로 저장하여 시간을 단축\n",
        "np.savez(\"./data/face/face.npz\", X=X_numpy, y=y_numpy)"
      ],
      "metadata": {
        "id": "B8ZsAZd0NC8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "npz_data = np.load(\"./data/face/face.npz\")\n",
        "X_numpy = npz_data['X']\n",
        "y_numpy = npz_data['y']"
      ],
      "metadata": {
        "id": "CjNHdH9aNFZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_numpy, y_numpy, test_size=0.2, random_state=1026)"
      ],
      "metadata": {
        "id": "n7wZFNDrNIxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "id": "jAyKQjHfNJrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불필요한 메모리 제거\n",
        "del X_numpy\n",
        "del y_numpy"
      ],
      "metadata": {
        "id": "a3sY8SwHNLA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageEmbedding = InceptionV3(\n",
        "                 include_top = False,\n",
        "                 weights=\"imagenet\",\n",
        "                 input_shape=(224,224,3), # 이미지 특징을 추출할 이미지 크기\n",
        "                 pooling=\"avg\")"
      ],
      "metadata": {
        "id": "Uvi73oI5NNDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_model = Sequential() # 뼈대 생성\n",
        "face_model.add(imageEmbedding) # 이미지 특징 추출 도구 연결\n",
        "face_model.add(Dense(units=128, activation=\"relu\")) # 원하는만큼 퍼셉트론(뉴런) 연결\n",
        "face_model.add(Dense(units=256, activation=\"relu\")) # 뉴런이 많을수록 모델의 학습 능력 증가\n",
        "face_model.add(Dense(units=128, activation=\"relu\")) # 다만 모델이 무거워짐\n",
        "face_model.add(Dense(units=8, activation=\"softmax\")) # 정답 데이터의 종류(class 수)와 맞춤"
      ],
      "metadata": {
        "id": "pkovrQLONO1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_model.summary()"
      ],
      "metadata": {
        "id": "8zVxABBBNQuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_model.compile(loss=\"sparse_categorical_crossentropy\", # 모델의 예측과 실제정답의 차이를 계산하는 알고리즘\n",
        "                     optimizer=\"adam\", # 모델의 최적화를 도와주는 경사하강법 알고리즘의 한 종류\n",
        "                     metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3xLx_ImJNZBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 조기학습 중단 : 모델이 일정 epoch내에 성능이 안 올라가면 자동으로 멈춰주는 기능(epoch 횟수 고민 X)\n",
        "early = EarlyStopping(monitor=\"val_accuracy\", # 모니터링 성능지표\n",
        "                      patience=5) # 인내심 횟수"
      ],
      "metadata": {
        "id": "XvlEVPQyNciX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 자동 저장 : 모델의 성능이 최고를 찍을 때 자동으로 중간중간 저장하는 기능(과대적합모델 생성방지)\n",
        "model_path = \"./data/face_model/face-{epoch:02d}-{val_accuracy:.2f}.hdf5\" # 모델이 저장될 경로 및 파일 이름\n",
        "mdckpt = ModelCheckpoint(filepath=model_path, # 파일경로 연결\n",
        "                         save_best_only=True, # 최고점일 때만 자동저장\n",
        "                         monitor=\"val_accuracy\") # 최고점을 판단하는 성능지표"
      ],
      "metadata": {
        "id": "sAKOJ3ZJNfRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_model.fit(X_train, y_train, # 학습용 문제, 답 설정\n",
        "                 validation_split = 0.2, # 검증용 데이터셋 비율 지정\n",
        "                 epochs = 1000, # 학습 반복 횟수 설정\n",
        "                 callbacks=[early, mdckpt], # 조기학습중단, 모델자동저장 연결\n",
        "                 batch_size=16) # 한번에 RAM메모리에 적재되는 데이터 수"
      ],
      "metadata": {
        "id": "dnLgFdpkNjpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best 모델로딩\n",
        "best_face_model = load_model(\"./data/face_model/face-21-0.78.hdf5\")"
      ],
      "metadata": {
        "id": "9n-GGBwwPm3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터 예측\n",
        "pre = best_animal_model.predict(X_test)"
      ],
      "metadata": {
        "id": "JM41633aPnJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류는\n",
        "pre[0]"
      ],
      "metadata": {
        "id": "8nSkAUimPnpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류평가지표 확인 (평가)\n",
        "print(classification_report(y_test.argmax(axis=1), pre.argmax(axis=1))) # 실제정답, 모델의 예측값"
      ],
      "metadata": {
        "id": "moV8LiXcPkjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XDVCnTA5QGoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from typing_extensions import Doc\n",
        "\n",
        "# 예측 알고리즘을 적용한 사용자 정의함수\n",
        "def my_predict(input_data) :\n",
        "  input_img = input_data.reshape(1,224,224,3)  # 1장의 이미지, 크기(224, 224), 컬러사진\n",
        "  pre = best_face_model.predict(input_img)  # 매개변수로 들어온 이미지를 모델에게 예측시킴\n",
        "  class_names = [\"차은우\",\"아이유\",\"조인성\",\"이정재\",\"문재인\",\"박해진\",\"류준열\",\"윤석열\"]\n",
        "  return class_names[pre.argmax(axis=1)[0]] # 확률중에 제일 높은 클래스번호를 글자로 변경\n",
        "\n",
        "demo = gr.Interface(my_predict, # 예측 함수 연결\n",
        "                    inputs= gr.Image(shape=(224,224)), # 생성될 입력 인터페이스 설정\n",
        "                    outputs= \"text\") # 생성될 출력 인터페이스 설정\n",
        "\n",
        "# 앱 실행\n",
        "demo.launch(share=True) # share 옵션 : 외부에서 접속 가능한 URL생성 (일시적)"
      ],
      "metadata": {
        "id": "XpVUs2MoP0Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JnIsJ7aNP0SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y5-jWRU1P0VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WvXYo9WbP0Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r53Yz5w1P0ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QORgTZcpP0cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KfP24GQLP0fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g6h7aiKjP0h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLfvL4FKP0kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HNZ8wi3kP0mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vY8NZGSJP0pJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}